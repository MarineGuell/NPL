"""
Script de test pour le tokenizer partagÃ© entre les modÃ¨les DL
VÃ©rifie que les deux modÃ¨les utilisent le mÃªme vocabulaire
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models import shared_tokenizer, DLModel, AutoencoderSummarizer, SharedTokenizer

def test_shared_tokenizer():
    """Test du tokenizer partagÃ©."""
    print("ğŸ§ª Test du tokenizer partagÃ©...")
    
    # Textes de test
    test_texts = [
        "L'intelligence artificielle rÃ©volutionne la technologie moderne.",
        "La biologie molÃ©culaire Ã©tudie les mÃ©canismes de la vie.",
        "L'astronomie explore les mystÃ¨res de l'univers."
    ]
    
    # Test du tokenizer partagÃ©
    print("ğŸ”„ EntraÃ®nement du tokenizer partagÃ©...")
    shared_tokenizer.fit_on_texts(test_texts)
    
    # VÃ©rification du vocabulaire
    word_index = shared_tokenizer.tokenizer.word_index
    print(f"ğŸ“š Taille du vocabulaire : {len(word_index)} mots")
    print(f"ğŸ”¤ Premiers mots du vocabulaire : {list(word_index.items())[:10]}")
    
    # Test de conversion
    sequences = shared_tokenizer.texts_to_sequences(test_texts)
    print(f"ğŸ“ SÃ©quences gÃ©nÃ©rÃ©es : {sequences}")
    
    return True

def test_dl_models_consistency():
    """Test de la cohÃ©rence entre les modÃ¨les DL."""
    print("\nğŸ§  Test de cohÃ©rence entre les modÃ¨les DL...")
    
    # Initialisation des modÃ¨les
    dl_model = DLModel()
    autoencoder = AutoencoderSummarizer()
    
    # VÃ©rification que les deux utilisent le mÃªme tokenizer
    print(f"ğŸ”— DLModel tokenizer : {type(dl_model.tokenizer)}")
    print(f"ğŸ”— Autoencoder tokenizer : {type(autoencoder.tokenizer)}")
    print(f"âœ… MÃªme instance : {dl_model.tokenizer is autoencoder.tokenizer}")
    
    # Test avec les mÃªmes textes
    test_text = "L'intelligence artificielle et la biologie molÃ©culaire."
    
    # Test DLModel
    if dl_model.tokenizer.is_fitted:
        dl_sequences = dl_model.tokenizer.texts_to_sequences([test_text])
        print(f"ğŸ“Š DLModel sÃ©quence : {dl_sequences}")
    
    # Test Autoencoder
    if autoencoder.tokenizer.is_fitted:
        auto_sequences = autoencoder.tokenizer.texts_to_sequences([test_text])
        print(f"ğŸ“Š Autoencoder sÃ©quence : {auto_sequences}")
        print(f"âœ… SÃ©quences identiques : {dl_sequences == auto_sequences}")
    
    return True

def test_save_load_tokenizer():
    """Test de sauvegarde et chargement du tokenizer."""
    print("\nğŸ’¾ Test de sauvegarde/chargement du tokenizer...")
    
    # Sauvegarde
    shared_tokenizer.save_tokenizer()
    
    # VÃ©rification que le fichier existe
    if os.path.exists(shared_tokenizer.TOKENIZER_PATH):
        print(f"âœ… Tokenizer sauvegardÃ© : {shared_tokenizer.TOKENIZER_PATH}")
        
        # Test de chargement
        new_tokenizer = SharedTokenizer()
        new_tokenizer.load_tokenizer()
        
        # VÃ©rification de la cohÃ©rence
        test_text = "Test de cohÃ©rence du tokenizer."
        original_seq = shared_tokenizer.texts_to_sequences([test_text])
        loaded_seq = new_tokenizer.texts_to_sequences([test_text])
        
        print(f"âœ… CohÃ©rence sauvegarde/chargement : {original_seq == loaded_seq}")
    else:
        print("âŒ Erreur : Le tokenizer n'a pas Ã©tÃ© sauvegardÃ©")
        return False
    
    return True

def main():
    """Fonction principale de test."""
    print("ğŸš€ Test du tokenizer partagÃ© entre les modÃ¨les DL...")
    print("="*60)
    
    try:
        # Tests
        test_shared_tokenizer()
        test_dl_models_consistency()
        test_save_load_tokenizer()
        
        print("\n" + "="*60)
        print("âœ… Tous les tests sont passÃ©s !")
        print("ğŸ¯ Le tokenizer partagÃ© fonctionne correctement.")
        print("ğŸ”— Les modÃ¨les DL utilisent maintenant le mÃªme vocabulaire.")
        
    except Exception as e:
        print(f"\nâŒ Erreur lors des tests : {e}")
        return False
    
    return True

if __name__ == "__main__":
    main() 