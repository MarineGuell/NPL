"""
Script d'Entra√Ænement Global - Chatbot Kaeru

Script principal pour entra√Æner tous les mod√®les du chatbot Kaeru en une seule commande.
Pipeline d'entra√Ænement complet et automatis√©.

Pipeline d'Entra√Ænement :
1. Chargement du dataset CSV (enriched_dataset_paragraphs.csv par d√©faut)
2. Nettoyage automatique (suppression doublons, valeurs manquantes)
3. S√©paration textes/labels pour l'entra√Ænement
4. Initialisation de l'orchestrateur (pr√©traitement + mod√®les)
5. Entra√Ænement s√©quentiel :
   - Mod√®le ML : Pipeline TF-IDF + Naive Bayes optimis√© par GridSearchCV
   - Mod√®le DL : LSTM bidirectionnel avec tokenizer partag√©
   - Autoencodeur : Entra√Ænement sur toutes les phrases du dataset avec tokenizer partag√©
6. Sauvegarde automatique de tous les mod√®les dans models/
7. √âvaluation et visualisations pour le mod√®le ML

Mod√®les Entra√Æn√©s :
- ml_model.joblib : Pipeline ML complet + vectorizer
- dl_model.h5 : Mod√®le LSTM + tokenizer partag√©
- dl_label_encoder.pkl : Label encoder pour le mod√®le DL
- autoencoder_summarizer.h5 : Autoencodeur + tokenizer partag√©
- shared_tokenizer.pkl : Tokenizer partag√© entre les mod√®les DL

Visualisations G√©n√©r√©es (app/plots/) :
- ml_confusion_matrix.png : Matrice de confusion
- ml_learning_curve.png : Courbe d'apprentissage

Usage :
    python app/train_models.py

Alternative modulaire :
    python app/train_models_modular.py --all          # Tous les mod√®les
    python app/train_models_modular.py --ml           # Mod√®le ML seulement
    python app/train_models_modular.py --dl           # Mod√®le DL seulement
    python app/train_models_modular.py --autoencoder  # Autoencodeur seulement

Configuration :
    Modifier DATASET_PATH pour changer le dataset d'entra√Ænement
    Tous les mod√®les sont pr√™ts pour l'inf√©rence apr√®s l'entra√Ænement
"""

import os
from utils import DataLoader
from chatbot import ChatbotOrchestrator

# === CHEMIN DU DATASET D'ENTRA√éNEMENT ===
DATASET_PATH = os.path.join(os.path.dirname(__file__), 'data', 'enriched_dataset_paragraphs.csv')

if __name__ == "__main__":
    print("üöÄ D√©but de l'entra√Ænement des mod√®les du chatbot Kaeru...")
    print(f"üìä Dataset utilis√© : {DATASET_PATH}")
    print("üîÑ Tokenizer partag√© entre les mod√®les DL pour la coh√©rence")
    print("üí° Pour un entra√Ænement modulaire, utilisez : python app/train_models_modular.py --help")
    
    # V√©rification de l'existence du dataset
    if not os.path.exists(DATASET_PATH):
        print(f"‚ùå Erreur : Le fichier {DATASET_PATH} n'existe pas!")
        print("üí° Veuillez d'abord ex√©cuter le script de collecte de donn√©es :")
        print("   python app/data/create_data.py")
        exit(1)
    
    # Chargement des donn√©es
    print(f"\nüìö Chargement du dataset : {DATASET_PATH}")
    loader = DataLoader(DATASET_PATH)
    texts, labels = loader.get_texts_and_labels()
    
    print(f"‚úÖ {len(texts)} textes charg√©s pour {len(set(labels))} cat√©gories")
    print(f"üìã Cat√©gories : {sorted(set(labels))}")

    # Initialisation de l'orchestrateur (pr√©traitement, mod√®les, autoencodeur)
    orchestrator = ChatbotOrchestrator()
    print("\n=== Entra√Ænement des mod√®les... ===")
    
    # Entra√Ænement global (ML, DL, autoencodeur r√©sum√©)
    orchestrator.train_models(texts, labels)
    
    print("\n" + "="*60)
    print("‚úÖ Entra√Ænement termin√© avec succ√®s!")
    print("üìÅ Mod√®les sauvegard√©s dans le dossier models/ :")
    print("   - ml_model.joblib (classification ML)")
    print("   - vectorizer.joblib (vectorizer TF-IDF)")
    print("   - dl_model.h5 (classification DL)")
    print("   - dl_label_encoder.pkl (label encoder DL)")
    print("   - autoencoder_summarizer.h5 (r√©sum√© DL)")
    print("   - shared_tokenizer.pkl (tokenizer partag√©)")
    print("\nüéØ Les mod√®les sont pr√™ts √† √™tre utilis√©s dans l'interface Streamlit!")
    print("üê∏ Kero! Votre chatbot est maintenant entra√Æn√©!") 