"""
Script Principal d'Entra√Ænement - Chatbot Kaeru

Script principal pour entra√Æner tous les mod√®les du chatbot Kaeru.
Permet d'entra√Æner tous les mod√®les ou un mod√®le sp√©cifique.
Sauvegarde automatique des mod√®les dans models/.
√âvaluation automatique des performances.

Usage :
    # Entra√Æner tous les mod√®les (recommand√©)
    python app/train_models.py --all
    
    # Entra√Æner un mod√®le sp√©cifique
    python app/train_models.py --model ml
    python app/train_models.py --model dl
    python app/train_models.py --model autoencoder
    
    # Entra√Æner et √©valuer automatiquement
    python app/train_models.py --all --evaluate
    
    # Afficher l'aide
    python app/train_models.py --help

Pipeline d'Entra√Ænement :
1. Chargement du dataset CSV (enriched_dataset_paragraphs.csv par d√©faut)
2. Nettoyage automatique (suppression doublons, valeurs manquantes)
3. Pr√©traitement des textes (nettoyage, normalisation, POS-tagging)
4. Entra√Ænement s√©quentiel :
   - Mod√®le ML : Pipeline TF-IDF + Naive Bayes optimis√© par GridSearchCV
   - Mod√®le DL : LSTM bidirectionnel avec tokenizer partag√©
   - Autoencodeur : Entra√Ænement sur toutes les phrases du dataset
5. Sauvegarde automatique de tous les mod√®les dans models/
6. √âvaluation et visualisations automatiques

Mod√®les Entra√Æn√©s :
- ml_model.joblib : Pipeline ML complet + vectorizer
- dl_model.h5 : Mod√®le LSTM + tokenizer partag√©
- dl_label_encoder.pkl : Label encoder pour le mod√®le DL
- autoencoder_summarizer.h5 : Autoencodeur + tokenizer partag√©
- shared_tokenizer.pkl : Tokenizer partag√© entre les mod√®les DL
"""

import os
import sys
import argparse
import pandas as pd
from datetime import datetime

# Ajout du chemin pour les imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils import DataLoader, TextPreprocessor
from models import MLModel, DLModel, AutoencoderSummarizer

def train_ml_model(texts, labels):
    """
    Entra√Æne le mod√®le ML.
    
    Args:
        texts: Les textes d'entra√Ænement
        labels: Les labels d'entra√Ænement
        
    Returns:
        MLModel: Le mod√®le entra√Æn√©
    """
    print("\n" + "="*60)
    print("ü§ñ ENTRA√éNEMENT DU MOD√àLE ML")
    print("="*60)
    
    ml_model = MLModel()
    ml_model.train(texts, labels)
    
    return ml_model

def train_dl_model(texts, labels):
    """
    Entra√Æne le mod√®le DL.
    
    Args:
        texts: Les textes d'entra√Ænement
        labels: Les labels d'entra√Ænement
        
    Returns:
        DLModel: Le mod√®le entra√Æn√©
    """
    print("\n" + "="*60)
    print("üß† ENTRA√éNEMENT DU MOD√àLE DL")
    print("="*60)
    
    dl_model = DLModel()
    X, y = dl_model.prepare(texts, labels)
    history, X_test, y_test = dl_model.train(X, y)
    
    return dl_model

def train_autoencoder(texts, labels):
    """
    Entra√Æne l'autoencodeur.
    
    Args:
        texts: Les textes d'entra√Ænement
        labels: Les labels d'entra√Ænement (non utilis√©s pour l'autoencodeur)
        
    Returns:
        AutoencoderSummarizer: L'autoencodeur entra√Æn√©
    """
    print("\n" + "="*60)
    print("üîÑ ENTRA√éNEMENT DE L'AUTOENCODEUR")
    print("="*60)
    
    # Pr√©traitement sp√©cial pour l'autoencodeur (pr√©serve les phrases)
    print("üîß Pr√©traitement sp√©cial pour l'autoencodeur...")
    preprocessor = TextPreprocessor()
    autoencoder_texts = preprocessor.transform_for_autoencoder(texts)
    
    print(f"üìù {len(autoencoder_texts)} textes pr√©trait√©s pour l'autoencodeur")
    
    # Afficher quelques exemples pour v√©rification
    print("\nüìã Exemples de textes pr√©trait√©s pour l'autoencodeur:")
    for i, text in enumerate(autoencoder_texts[:3]):
        print(f"   {i+1}. {text[:100]}...")
    
    autoencoder = AutoencoderSummarizer()
    autoencoder.train(autoencoder_texts)
    
    # √âvaluation automatique de l'autoencodeur (comme pour ML et DL)
    print("\nüìä √âVALUATION AUTOMATIQUE DE L'AUTOENCODEUR")
    print("="*60)
    autoencoder.evaluate()
    
    return autoencoder

def evaluate_models(ml_model=None, dl_model=None, autoencoder=None):
    """
    √âvalue les mod√®les entra√Æn√©s.
    
    Args:
        ml_model: Le mod√®le ML (optionnel)
        dl_model: Le mod√®le DL (optionnel)
        autoencoder: L'autoencodeur (optionnel) - d√©j√† √©valu√© automatiquement
    """
    print("\n" + "="*60)
    print("üìä √âVALUATION DES MOD√àLES")
    print("="*60)
    
    if ml_model:
        ml_model.evaluate()
    
    if dl_model:
        dl_model.evaluate()
    
    # L'autoencodeur est d√©j√† √©valu√© automatiquement apr√®s l'entra√Ænement
    if autoencoder:
        print("‚úÖ Autoencodeur d√©j√† √©valu√© automatiquement apr√®s l'entra√Ænement")

def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="Script d'entra√Ænement modulaire pour le chatbot Kaeru",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation :
  python app/train_models.py --all                    # Entra√Æner tous les mod√®les
  python app/train_models.py --model ml               # Entra√Æner seulement le mod√®le ML
  python app/train_models.py --model dl               # Entra√Æner seulement le mod√®le DL
  python app/train_models.py --model autoencoder      # Entra√Æner seulement l'autoencodeur
  python app/train_models.py --all --evaluate         # Entra√Æner et √©valuer tous les mod√®les
        """
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='Entra√Æner tous les mod√®les (ML, DL, Autoencodeur)'
    )
    
    parser.add_argument(
        '--model',
        choices=['ml', 'dl', 'autoencoder'],
        help='Entra√Æner un mod√®le sp√©cifique'
    )
    
    parser.add_argument(
        '--evaluate',
        action='store_true',
        help='√âvaluer automatiquement les mod√®les apr√®s entra√Ænement'
    )
    
    parser.add_argument(
        '--dataset',
        default='data/enriched_dataset_paragraphs_2.csv',
        help='Chemin vers le dataset (d√©faut: data/enriched_dataset_paragraphs_2.csv)'
    )
    
    args = parser.parse_args()
    
    # V√©rification des arguments
    if not args.all and not args.model:
        parser.error("Vous devez sp√©cifier --all ou --model")
    
    if args.all and args.model:
        parser.error("Vous ne pouvez pas utiliser --all et --model en m√™me temps")
    
    # Chemin du dataset
    dataset_path = os.path.join(os.path.dirname(__file__), args.dataset)
    
    if not os.path.exists(dataset_path):
        print(f"‚ùå Erreur : Le fichier {dataset_path} n'existe pas!")
        print("üí° Assurez-vous d'avoir cr√©√© le dataset avec create_data.py")
        return
    
    print("üöÄ D√âMARRAGE DE L'ENTRA√éNEMENT MODULAIRE")
    print("="*60)
    print(f"üìÅ Dataset : {dataset_path}")
    print(f"‚è∞ D√©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Chargement des donn√©es
    print("\nüìö Chargement des donn√©es...")
    loader = DataLoader(dataset_path)
    texts, labels = loader.get_texts_and_labels()
    
    # Pr√©traitement
    print("üîß Pr√©traitement des textes...")
    preprocessor = TextPreprocessor()
    processed_texts = preprocessor.transform(texts)
    
    print(f"‚úÖ {len(processed_texts)} textes pr√©trait√©s pour {len(set(labels))} cat√©gories")
    
    # Variables pour stocker les mod√®les entra√Æn√©s
    ml_model = None
    dl_model = None
    autoencoder = None
    
    # Entra√Ænement selon les arguments
    if args.all:
        print("\nüéØ ENTRA√éNEMENT DE TOUS LES MOD√àLES")
        print("="*60)
        
        # Entra√Ænement ML
        ml_model = train_ml_model(processed_texts, labels)
        
        # Entra√Ænement DL
        dl_model = train_dl_model(processed_texts, labels)
        
        # Entra√Ænement Autoencodeur
        autoencoder = train_autoencoder(processed_texts, labels)
        
    elif args.model == 'ml':
        print("\nüéØ ENTRA√éNEMENT DU MOD√àLE ML")
        print("="*60)
        ml_model = train_ml_model(processed_texts, labels)
        
    elif args.model == 'dl':
        print("\nüéØ ENTRA√éNEMENT DU MOD√àLE DL")
        print("="*60)
        dl_model = train_dl_model(processed_texts, labels)
        
    elif args.model == 'autoencoder':
        print("\nüéØ ENTRA√éNEMENT DE L'AUTOENCODEUR")
        print("="*60)
        autoencoder = train_autoencoder(processed_texts, labels)
    
    # √âvaluation si demand√©e
    if args.evaluate:
        evaluate_models(ml_model, dl_model, autoencoder)
    
    print("\n" + "="*60)
    print("üéâ ENTRA√éNEMENT TERMIN√â !")
    print("="*60)
    print(f"‚è∞ Fin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # R√©sum√© des mod√®les entra√Æn√©s
    print("\nüìã R√âSUM√â DES MOD√àLES :")
    if ml_model:
        print("‚úÖ Mod√®le ML (TF-IDF + Naive Bayes) - models/ml_model.joblib")
        print("   üìä Performances g√©n√©r√©es dans app/performances/")
    if dl_model:
        print("‚úÖ Mod√®le DL (LSTM) - models/dl_model.h5")
        print("‚úÖ Label Encoder DL - models/dl_label_encoder.pkl")
        print("   üìä Performances g√©n√©r√©es dans app/performances/")
    if autoencoder:
        print("‚úÖ Autoencodeur - models/autoencoder_summarizer.h5")
        print("   üìä Performances g√©n√©r√©es dans app/performances/")
    
    print("\nüí° Pour √©valuer les performances :")
    print("   python app/evaluate_all_models.py")
    print("\nüí° Pour utiliser le chatbot :")
    print("   streamlit run app/interface.py")

if __name__ == "__main__":
    main() 