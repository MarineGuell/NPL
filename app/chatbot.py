"""
Module principal du chatbot Kaeru - Orchestrateur des mod√®les ML/DL.

Ce module centralise l'utilisation des diff√©rents mod√®les (ML et DL) pour la classification
et le r√©sum√© de textes. Il g√®re le chargement des mod√®les, le pr√©traitement des donn√©es
et l'orchestration des pr√©dictions.
"""

import numpy as np
from transformers import pipeline
from utils import DataLoader, TextPreprocessor, normalize_text
from model_tfidf import MLModel
from model_lstm import DLModel
from model_autoencodeur import AutoencoderSummarizer

class TextProcessor:
    """
    Orchestrateur principal pour le traitement de textes avec les mod√®les ML/DL.
    
    Cette classe centralise l'utilisation des mod√®les de classification et de r√©sum√©,
    g√®re le pr√©traitement des donn√©es et fournit une interface unifi√©e pour les pr√©dictions.
    """
    
    def __init__(self, data_path="app\data\enriched_dataset_paragraphs_2.csv"):
        """
        Initialise l'orchestrateur avec les mod√®les et les donn√©es.
        
        Args:
            data_path (str): Chemin vers le fichier de donn√©es CSV
        """
        self.loader = DataLoader(data_path)
        self.preprocessor = TextPreprocessor()
        self.ml_classifier = MLModel()
        self.dl_classifier = DLModel()
        self.autoencoder = AutoencoderSummarizer()
        self.summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
        self.initialized = False

    def initialize(self):
        """
        Initialise les mod√®les en chargeant et pr√©traitant les donn√©es.
        Ne r√©entra√Æne pas si les mod√®les sont d√©j√† charg√©s depuis le disque.
        """
        if self.initialized:
            return

        # Si les mod√®les sont d√©j√† charg√©s, on ne r√©entra√Æne pas
        if self.ml_classifier.model is not None and self.dl_classifier.model is not None:
            self.initialized = True
            return

        print("üîÑ Chargement des donn√©es...")
        texts, labels = self.loader.get_texts_and_labels()
        
        print("üîÑ Pr√©traitement des textes...")
        clean_texts = self.preprocessor.transform(texts)
        
        print("üîÑ Division des donn√©es...")
        X_train, X_test, y_train, y_test = self.loader.split_data(clean_texts, labels)
        
        print("üîÑ Entra√Ænement du mod√®le ML...")
        self.ml_classifier.train(X_train, y_train)
        
        print("üîÑ Pr√©paration des donn√©es pour le mod√®le DL...")
        X_dl, y_dl = self.dl_classifier.prepare(clean_texts, labels)
        
        print("üîÑ Entra√Ænement du mod√®le DL...")
        history, X_test_dl, y_test_dl = self.dl_classifier.train(X_dl, y_dl)
        
        print("‚úÖ Initialisation termin√©e !")
        self.initialized = True

    def process_text(self, text, task="classification", model_type="ml"):
        """
        Traite un texte selon la t√¢che et le type de mod√®le sp√©cifi√©s.
        """
        print("Initialisation")
        try:
            if not self.initialized:
                self.initialize()
            # Pr√©traitement du texte
            clean_text = self.preprocessor.clean(text)
            normalized_text = normalize_text(clean_text)
            result = {
                "original_text": text,
                "cleaned_text": clean_text,
                "normalized_text": normalized_text
            }
            if task == "classification":
                if model_type == "ml":
                    print('Initialisation - Classification - Machine Learning')
                    prediction = self.ml_classifier.predict([normalized_text])[0]
                    probabilities = self.ml_classifier.predict_proba([normalized_text])[0]
                    result.update({
                        "task": "classification",
                        "model": "ml",
                        "prediction": prediction,
                        "confidence": float(max(probabilities)),
                        "probabilities": probabilities.tolist()
                    })
                else:
                    print('Initialisation - Classification - Deep Learning')
                    prediction = self.dl_classifier.predict([normalized_text])[0]
                    probabilities = self.dl_classifier.predict_proba([normalized_text])[0]
                    result.update({
                        "task": "classification",
                        "model": "dl",
                        "prediction": prediction,
                        "confidence": float(max(probabilities)),
                        "probabilities": probabilities.tolist()
                    })
            elif task == "summarization":
                if model_type == "ml":                    
                    print('Initialisation - R√©sum√© - Machine Learning')
                    from sklearn.feature_extraction.text import TfidfVectorizer
                    from nltk.tokenize import sent_tokenize
                    sentences = sent_tokenize(text)
                    vectorizer = TfidfVectorizer(stop_words='english')
                    tfidf_matrix = vectorizer.fit_transform(sentences)
                    sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)
                    num_sentences = min(3, len(sentences))
                    top_indices = sentence_scores.argsort()[-num_sentences:][::-1]
                    top_indices.sort()
                    summary = " ".join([sentences[i] for i in top_indices])
                    important_words = []
                    if self.ml_classifier.vectorizer is not None:
                        clean_text = self.preprocessor.clean(text)
                        X = self.ml_classifier.vectorizer.transform([clean_text])
                        feature_names = self.ml_classifier.vectorizer.get_feature_names_out()
                        scores = X.toarray()[0]
                        top_indices_words = scores.argsort()[-5:][::-1]
                        important_words = [feature_names[i] for i in top_indices_words if scores[i] > 0]
                    result.update({
                        "task": "summarization",
                        "model": "ml",
                        "summary": summary,
                        "important_words": important_words
                    })
                else:
                    print('Initialisation - Classification - Deep Learning')
                    summary = self.summarizer(normalized_text, 
                                            max_length=130, 
                                            min_length=30, 
                                            do_sample=False)[0]['summary_text']
                    result.update({
                        "task": "summarization",
                        "model": "dl",
                        "summary": summary
                    })
            print("Termin√©")
            return result
        except Exception as e:
            return {"error": f"Erreur lors du traitement : {e}"}

    def classify(self, text, model_type='ml'):
        """
        Classification d'un texte avec le mod√®le ML ou DL.
        Retourne une cha√Æne format√©e pour l'interface.
        """
        result = self.process_text(text, task='classification', model_type=model_type)
        label = result.get('prediction', 'N/A')
        confidence = result.get('confidence', 0)
        return f"Pr√©diction : {label}\nConfiance : {confidence:.2f}"

    def summarize(self, text, model_type='ml'):
        """
        R√©sum√© d'un texte avec le mod√®le ML ou DL.
        Retourne une cha√Æne format√©e pour l'interface.
        """
        result = self.process_text(text, task='summarization', model_type=model_type)
        summary = result.get('summary', '')
        if model_type == 'ml' and result.get('important_words'):
            mots = result['important_words']
            mots_str = ', '.join(mots)
            return f"R√©sum√© : {summary}\n\nMots-cl√©s importants : {mots_str}"
        return summary
