"""
Module principal du chatbot pour la classification et le r√©sum√© de texte.
"""

import os
import numpy as np
from utils import DataLoader, TextPreprocessor, encode_labels, normalize_text
from model_autoencodeur import AutoencoderSummarizer
from model_lstm import DLModel
from model_tfidf import MLModel

from transformers import pipeline
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.feature_extraction.text import CountVectorizer
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re

class TextProcessor:
    """
    Classe principale pour le traitement de texte.
    G√®re l'initialisation, l'entra√Ænement et l'utilisation des diff√©rents mod√®les.
    """
    
    def __init__(self, data_path="app\data\enriched_dataset_paragraphs_2.csv"):
        """
        Initialise le processeur de texte.
        
        Args:
            data_path (str): Chemin vers le fichier de donn√©es
        """
        self.data_path = data_path
        self.ml_classifier = MLModel()
        self.dl_classifier = DLModel()
        self.preprocessor = TextPreprocessor()
        self.loader = DataLoader(data_path)
        self.initialized = False
        
        # Initialisation du mod√®le de r√©sum√©
        self.summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
        
        # T√©l√©chargement des ressources NLTK n√©cessaires
        nltk.download('punkt')
        nltk.download('stopwords')
        self.stop_words = set(stopwords.words('english'))
        
    def extract_keywords_lda(self, text, n_topics=3, n_words=5):
        """
        Extrait les mots-cl√©s d'un texte en utilisant LDA.
        
        Args:
            text (str): Le texte √† analyser
            n_topics (int): Nombre de topics √† extraire
            n_words (int): Nombre de mots-cl√©s par topic
            
        Returns:
            list: Liste des mots-cl√©s extraits
        """
        # Pr√©traitement du texte
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)
        tokens = word_tokenize(text)
        tokens = [t for t in tokens if t not in self.stop_words and len(t) > 2]
        
        # Cr√©ation du vecteur de comptage
        vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')
        X = vectorizer.fit_transform([text])
        
        # Application de LDA
        lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
        lda.fit(X)
        
        # Extraction des mots-cl√©s
        feature_names = vectorizer.get_feature_names_out()
        keywords = []
        
        for topic_idx, topic in enumerate(lda.components_):
            top_words_idx = topic.argsort()[:-n_words-1:-1]
            top_words = [feature_names[i] for i in top_words_idx]
            keywords.extend(top_words)
            
        return list(set(keywords))  # Suppression des doublons
        
    def summarize_with_keywords(self, text):
        """
        Cr√©e un r√©sum√© bas√© sur les mots-cl√©s extraits.
        
        Args:
            text (str): Le texte √† r√©sumer
            
        Returns:
            str: Le r√©sum√© avec les mots-cl√©s
        """
        keywords = self.extract_keywords_lda(text)
        summary = f"Ce texte parle de {', '.join(keywords[:-1])} et {keywords[-1]} kero üê∏"
        return summary

    def initialize(self):
        """
        Initialise les mod√®les en chargeant et pr√©traitant les donn√©es.
        Ne r√©entra√Æne pas si les mod√®les sont d√©j√† charg√©s depuis le disque.
        """
        if self.initialized:
            return

        # Si les mod√®les sont d√©j√† charg√©s, on ne r√©entra√Æne pas
        if self.ml_classifier.model is not None and self.dl_classifier.model is not None:
            self.initialized = True
            return

        print("üîÑ Chargement des donn√©es...")
        texts, labels = self.loader.get_texts_and_labels()
        
        print("üîÑ Pr√©traitement des textes...")
        clean_texts = self.preprocessor.transform(texts)
        
        print("üîÑ Division des donn√©es...")
        X_train, X_test, y_train, y_test = self.loader.split_data(clean_texts, labels)
        
        print("üîÑ Entra√Ænement du mod√®le ML...")
        self.ml_classifier.train(X_train, y_train)
        
        print("üîÑ Pr√©paration des donn√©es pour le mod√®le DL...")
        X_dl, y_dl = self.dl_classifier.prepare(clean_texts, labels)
        
        print("üîÑ Entra√Ænement du mod√®le DL...")
        history, X_test_dl, y_test_dl = self.dl_classifier.train(X_dl, y_dl)
        
        print("‚úÖ Initialisation termin√©e !")
        self.initialized = True

    def process_text(self, text, task="classification", model_type="ml"):
        """
        Traite un texte selon la t√¢che et le type de mod√®le sp√©cifi√©s.
        """
        print("Initialisation")
        try:
            if not self.initialized:
                self.initialize()
            # Pr√©traitement du texte
            clean_text = self.preprocessor.clean(text)
            normalized_text = normalize_text(clean_text)
            result = {
                "original_text": text,
                "cleaned_text": clean_text,
                "normalized_text": normalized_text
            }
            if task == "classification":
                if model_type == "ml":
                    print('Initialisation - Classification - Machine Learning')
                    prediction = self.ml_classifier.predict([normalized_text])[0]
                    probabilities = self.ml_classifier.predict_proba([normalized_text])[0]
                    result.update({
                        "task": "classification",
                        "model": "ml",
                        "prediction": prediction,
                        "confidence": float(max(probabilities)),
                        "probabilities": probabilities.tolist()
                    })
                else:
                    print('Initialisation - Classification - Deep Learning')
                    prediction = self.dl_classifier.predict([normalized_text])[0]
                    probabilities = self.dl_classifier.predict_proba([normalized_text])[0]
                    result.update({
                        "task": "classification",
                        "model": "dl",
                        "prediction": prediction,
                        "confidence": float(max(probabilities)),
                        "probabilities": probabilities.tolist()
                    })
            elif task == "summarization":
                if model_type == "ml":                    
                    print('Initialisation - R√©sum√© - Machine Learning')
                    from sklearn.feature_extraction.text import TfidfVectorizer
                    from nltk.tokenize import sent_tokenize
                    sentences = sent_tokenize(text)
                    vectorizer = TfidfVectorizer(stop_words='english')
                    tfidf_matrix = vectorizer.fit_transform(sentences)
                    sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)
                    num_sentences = min(3, len(sentences))
                    top_indices = sentence_scores.argsort()[-num_sentences:][::-1]
                    top_indices.sort()
                    summary = " ".join([sentences[i] for i in top_indices])
                    important_words = []
                    if self.ml_classifier.vectorizer is not None:
                        clean_text = self.preprocessor.clean(text)
                        X = self.ml_classifier.vectorizer.transform([clean_text])
                        feature_names = self.ml_classifier.vectorizer.get_feature_names_out()
                        scores = X.toarray()[0]
                        top_indices_words = scores.argsort()[-5:][::-1]
                        important_words = [feature_names[i] for i in top_indices_words if scores[i] > 0]
                    result.update({
                        "task": "summarization",
                        "model": "ml",
                        "summary": summary,
                        "important_words": important_words
                    })
                else:
                    print('Initialisation - Classification - Deep Learning')
                    summary = self.summarizer(normalized_text, 
                                            max_length=130, 
                                            min_length=30, 
                                            do_sample=False)[0]['summary_text']
                    result.update({
                        "task": "summarization",
                        "model": "dl",
                        "summary": summary
                    })
            elif task == "keywords":
                summary = self.summarize_with_keywords(text)
                result.update({
                    "task": "keywords",
                    "model": "lda",
                    "summary": summary
                })
            return result
        except Exception as e:
            return {"error": f"Erreur lors du traitement : {e}"}

    def evaluate_models(self):
        """
        √âvalue les mod√®les sur les donn√©es de test.
        """
        if not self.initialized:
            self.initialize()
        
        print("\n√âvaluation du mod√®le ML :")
        self.ml_classifier.evaluate(X_test, y_test)
        
        print("\n√âvaluation du mod√®le DL :")
        self.dl_classifier.evaluate(X_test_dl, y_test_dl)

    def cleanup(self):
        """
        Nettoie les ressources utilis√©es par les mod√®les.
        """
        if hasattr(self.dl_classifier, 'model'):
            del self.dl_classifier.model
        if hasattr(self.dl_classifier, 'tokenizer'):
            del self.dl_classifier.tokenizer
        self.initialized = False

    def classify(self, text, model_type='ml'):
        """
        Classification d'un texte avec le mod√®le ML ou DL.
        Retourne une cha√Æne format√©e pour l'interface.
        """
        result = self.process_text(text, task='classification', model_type=model_type)
        label = result.get('prediction', 'N/A')
        confidence = result.get('confidence', 0)
        return f"Pr√©diction : {label}\nConfiance : {confidence:.2f}"

    def summarize(self, text, model_type='ml'):
        """
        R√©sum√© d'un texte avec le mod√®le ML ou DL.
        Retourne une cha√Æne format√©e pour l'interface.
        """
        result = self.process_text(text, task='summarization', model_type=model_type)
        summary = result.get('summary', '')
        if model_type == 'ml' and result.get('important_words'):
            mots = result['important_words']
            mots_str = ', '.join(mots)
            return f"R√©sum√© : {summary}\n\nMots-cl√©s importants : {mots_str}"
        return summary

# if __name__ == "__main__":
#     # Test simple du processeur
#     processor = TextProcessor()
#     processor.initialize()
    
#     # Exemples de textes √† traiter
#     sample_texts = [
#         "Cricket Australia is set to begin the team's pre-season...",
#         "Additionally, the microsite on Amazon.in highlights...",
#         "Having undergone a surgery for shoulder dislocation..."
#     ]
    
#     print("\nClassification avec le mod√®le ML :")
#     for text in sample_texts:
#         result = processor.process_text(text, task="classification", model_type="ml")
#         print(f"\nTexte : {text[:50]}...")
#         print(f"Pr√©diction : {result['prediction']}")
#         print(f"Confiance : {result['confidence']:.2f}")
    
#     print("\nClassification avec le mod√®le DL :")
#     for text in sample_texts:
#         result = processor.process_text(text, task="classification", model_type="dl")
#         print(f"\nTexte : {text[:50]}...")
#         print(f"Pr√©diction : {result['prediction']}")
#         print(f"Confiance : {result['confidence']:.2f}")
    
#     print("\nR√©sum√© avec le mod√®le ML :")
#     for text in sample_texts:
#         result = processor.process_text(text, task="summarization", model_type="ml")
#         print(f"\nTexte : {text[:50]}...")
#         print(f"R√©sum√© : {result['summary']}")
    
#     print("\nR√©sum√© avec le mod√®le DL :")
#     for text in sample_texts:
#         result = processor.process_text(text, task="summarization", model_type="dl")
#         print(f"\nTexte : {text[:50]}...")
#         print(f"R√©sum√© : {result['summary']}")
    
#     print("\nR√©sum√© bas√© sur les mots-cl√©s :")
#     for text in sample_texts:
#         result = processor.process_text(text, task="keywords", model_type="lda")
#         print(f"\nTexte : {text[:50]}...")
#         print(f"R√©sum√© : {result['summary']}")
    
#     processor.cleanup() 