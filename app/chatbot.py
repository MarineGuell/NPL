import joblib
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import os
from typing import Optional, Dict, Any
import numpy as np

from utils import summarize_text, search_wikipedia

# T√©l√©chargement des ressources NLTK n√©cessaires
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

class Chatbot:
    def __init__(self):
        self.model_name = "microsoft/DialoGPT-medium"
        self.tokenizer = None
        self.model = None
        self.classifier_model = None
        self.vectorizer = None
        self.initialize_models()

    def create_base_model(self):
        """Cr√©e un mod√®le de classification de base"""
        print("üîÑ Cr√©ation d'un mod√®le de classification de base...")
        
        # Donn√©es d'exemple pour l'entra√Ænement
        texts = [
            "Bonjour, comment puis-je vous aider ?",
            "Quelle est la m√©t√©o aujourd'hui ?",
            "Pouvez-vous me donner des informations sur Python ?",
            "Je cherche des recettes de cuisine",
            "Comment fonctionne l'intelligence artificielle ?",
            "Quelles sont les derni√®res nouvelles ?",
            "Je voudrais apprendre √† programmer",
            "Pouvez-vous m'aider avec mes devoirs ?",
            "Je cherche des informations sur l'histoire",
            "Comment faire du sport √† la maison ?"
        ]
        
        # Cat√©gories correspondantes
        categories = [
            "accueil",
            "m√©t√©o",
            "technologie",
            "cuisine",
            "technologie",
            "actualit√©s",
            "√©ducation",
            "√©ducation",
            "histoire",
            "sport"
        ]
        
        # Cr√©ation et entra√Ænement du vectoriseur
        self.vectorizer = TfidfVectorizer()
        X = self.vectorizer.fit_transform(texts)
        
        # Cr√©ation et entra√Ænement du mod√®le
        self.classifier_model = MultinomialNB()
        self.classifier_model.fit(X, categories)
        
        # Sauvegarde des mod√®les
        os.makedirs("app", exist_ok=True)
        joblib.dump(self.classifier_model, "app/model.joblib")
        joblib.dump(self.vectorizer, "app/vectorizer.joblib")
        
        print("‚úÖ Mod√®le de base cr√©√© et sauvegard√© !")

    def initialize_models(self):
        """Initialise tous les mod√®les n√©cessaires"""
        try:
            print("üîÑ Chargement des mod√®les...")
            
            # Chargement du mod√®le DialoGPT
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(self.model_name)
            
            # Chargement du mod√®le de classification
            model_path = "app/model.joblib"
            vectorizer_path = "app/vectorizer.joblib"
            
            if os.path.exists(model_path) and os.path.exists(vectorizer_path):
                self.classifier_model = joblib.load(model_path)
                self.vectorizer = joblib.load(vectorizer_path)
            else:
                print("‚ö†Ô∏è Mod√®les de classification non trouv√©s. Cr√©ation d'un mod√®le de base...")
                self.create_base_model()
            
            print("‚úÖ Mod√®les charg√©s avec succ√®s !")
        except Exception as e:
            print(f"‚ùå Erreur lors de l'initialisation des mod√®les: {str(e)}")
            raise

    def preprocess_text(self, text: str) -> str:
        """Pr√©traite le texte pour la classification"""
        text = text.lower()
        text = text.translate(str.maketrans('', '', string.punctuation))
        tokens = word_tokenize(text)
        tokens = [word for word in tokens if word not in stopwords.words('english')]
        tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens]
        return " ".join(tokens)

    def generate_response(self, user_input: str) -> Dict[str, Any]:
        """G√©n√®re une r√©ponse bas√©e sur l'entr√©e de l'utilisateur"""
        try:
            response = {
                "text": "",
                "category": None,
                "confidence": None
            }
            
            # Classification si le mod√®le est disponible
            if self.classifier_model and self.vectorizer:
                clean_text = self.preprocess_text(user_input)
                vect = self.vectorizer.transform([clean_text])
                prediction = self.classifier_model.predict(vect)[0]
                confidence = self.classifier_model.predict_proba(vect).max()
                response["category"] = prediction
                response["confidence"] = float(confidence)
            
            # G√©n√©ration de r√©ponse avec DialoGPT
            input_ids = self.tokenizer.encode(user_input + self.tokenizer.eos_token, 
                                            return_tensors='pt')
            
            output = self.model.generate(
                input_ids,
                max_length=1000,
                pad_token_id=self.tokenizer.eos_token_id,
                no_repeat_ngram_size=3,
                do_sample=True,
                top_k=100,
                top_p=0.7,
                temperature=0.8
            )
            
            response["text"] = self.tokenizer.decode(output[:, input_ids.shape[-1]:][0], 
                                                   skip_special_tokens=True)
            
            return response
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}")
            return {
                "text": "D√©sol√©, une erreur s'est produite. Veuillez r√©essayer.",
                "category": None,
                "confidence": None
            }

    def cleanup(self):
        """Nettoie les ressources"""
        if self.model:
            del self.model
        if self.tokenizer:
            del self.tokenizer
        if self.classifier_model:
            del self.classifier_model
        if self.vectorizer:
            del self.vectorizer
        torch.cuda.empty_cache() if torch.cuda.is_available() else None


if __name__ == "__main__":
    # Test simple du chatbot
    chatbot = Chatbot()
    print("ü§ñ Chatbot initialis√© ! Tapez 'quit' pour quitter.")
    
    while True:
        user_input = input("Vous : ")
        if user_input.lower() in ["quit", "exit", "bye"]:
            print("Chatbot : Au revoir !")
            chatbot.cleanup()
            break
            
        response = chatbot.generate_response(user_input)
        print("Chatbot :", response)
