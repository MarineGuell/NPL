# ğŸ¸ Kaeru FrogBot


## FonctionnalitÃ©s Principales

### 1. Classification de Texte
- **Classification ML** : Pipeline TF-IDF + Naive Bayes optimisÃ© par GridSearchCV
- **Classification DL** : RÃ©seau LSTM bidirectionnel avec BatchNormalization

### 2. RÃ©sumÃ© de Texte
- **RÃ©sumÃ© ML** : MÃ©thode extractive basÃ©e sur la similaritÃ© cosinus TF-IDF
- **RÃ©sumÃ© DL** : Autoencodeur extractif (sÃ©lection des phrases les mieux reconstruites)

### 3. Recherche Wikipedia Intelligente
- Extraction automatique des mots-clÃ©s importants
- Recherche intelligente avec gestion de l'ambiguÃ¯tÃ©
- Interface interactive pour la sÃ©lection des pages

### Structure du Projet
```
NLP/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ interface.py           # Interface Streamlit (5 fonctions)
â”‚   â”œâ”€â”€ chatbot.py             # Orchestrateur principal
â”‚   â”œâ”€â”€ model_tfidf.py         # ModÃ¨les Machine Learning
â”‚   â”œâ”€â”€ model_autoencodeur.py  # ModÃ¨les Autoencodeur
â”‚   â”œâ”€â”€ model_lstm.py          # ModÃ¨les Deep Learning
â”‚   â”œâ”€â”€ train_ml.py            # Entrainement ModÃ¨les Machine Learning
â”‚   â”œâ”€â”€ train_autoencodeur.py  # Entrainement ModÃ¨les Autoencodeur
â”‚   â”œâ”€â”€ train_dl.py            # Entrainement ModÃ¨les Deep Learning
â”‚   â”œâ”€â”€ mon_tokenizer.py       # Tokenizer
â”‚   â”œâ”€â”€ wikipedia_search.py    # Wikipedia
â”‚   â”œâ”€â”€ utils.py               # PrÃ©traitement et utilitaires
â”‚   â”œâ”€â”€ models/                # Modeles entrainÃ©s enregistrÃ©s
â”‚   â”œâ”€â”€ performances/          # evaluation des Modeles entrainÃ©s enregistrÃ©s
â”‚   â”œâ”€â”€ data/                  # Datasets d'entraÃ®nement
â”‚   â”œâ”€â”€ plots/                 # Visualisations (matrices, courbes, comparaisons)
â”‚   â””â”€â”€ static/                # CSS
â”œâ”€â”€ requirements.txt           # DÃ©pendances
â””â”€â”€ README.md                  # Documentation
```

## ğŸ› ï¸ Installation et Configuration

### PrÃ©requis
- Python 3.8+
- TensorFlow 2.x
- Scikit-learn
- Streamlit
- NLTK

### Installation
```bash
# Cloner le repository
git clone [URL_DU_REPO]
cd NLP

# CrÃ©er l'environnement virtuel
python -m venv venv
# Activer l'environnement
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger les ressources NLTK
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt')"
```

## Utilisation

### Interface Utilisateur
```bash
# Lancer l'interface Streamlit
streamlit run app/interface.py
```

## ğŸ”§ DÃ©tail des FonctionnalitÃ©s

### Classification ML (TF-IDF + Naive Bayes)
- **PrÃ©traitement** : Nettoyage complet (ponctuation, URLs, emails, stopwords, lemmatisation)
- **Vectorisation** : TF-IDF avec bigrammes et optimisation des hyperparamÃ¨tres
- **ModÃ¨le** : Naive Bayes optimisÃ© par GridSearchCV
- **Ã‰valuation** : Matrice de confusion, courbe d'apprentissage, rapport de classification

### Classification DL (LSTM Bidirectionnel)
- **PrÃ©traitement** : MÃªme pipeline que ML + tokenization Keras
- **Architecture** : Embedding â†’ LSTM Bidirectionnel â†’ BatchNormalization â†’ Dense
- **EntraÃ®nement** : Early stopping, validation split, sauvegarde automatique
- **InfÃ©rence** : Chargement du modÃ¨le, tokenizer et encoder

### RÃ©sumÃ© ML (SimilaritÃ© Cosinus)
- **Processus** : DÃ©coupage en phrases â†’ Vectorisation TF-IDF â†’ Calcul similaritÃ© cosinus
- **SÃ©lection** : 3 phrases les plus similaires au texte global
- **PrÃ©servation** : Ordre original des phrases pour la cohÃ©rence narrative

### RÃ©sumÃ© DL (Autoencodeur Extractif)
- **Processus** : DÃ©coupage en phrases â†’ Vectorisation â†’ Autoencodeur â†’ Erreur reconstruction
- **SÃ©lection** : Phrases avec l'erreur de reconstruction la plus faible
- **Architecture** : Embedding â†’ LSTM â†’ Dense â†’ RepeatVector â†’ LSTM â†’ TimeDistributed

### Recherche Wikipedia Intelligente
- **Extraction** : Mots-clÃ©s TF-IDF du texte utilisateur
- **Recherche** : Pages Wikipedia correspondantes
- **Gestion** : AmbiguÃ¯tÃ© avec boutons interactifs
- **RÃ©sultat** : RÃ©sumÃ© Wikipedia formatÃ©

## ğŸ“Š entrainement, sauvegarde et performances

### EntraÃ®nement
1. Chargement du dataset CSV
2. Nettoyage (doublons, valeurs manquantes)
3. PrÃ©traitement global (TextPreprocessor)
4. EntraÃ®nement ML (GridSearchCV + Ã©valuation)
5. EntraÃ®nement DL (LSTM + sauvegarde tokenizer/encoder)
6. EntraÃ®nement autoencodeur (phrases du dataset)
7. Sauvegarde de tous les modÃ¨les dans `models/`
Dans le dossier performances/

### Fichiers SauvegardÃ©s (dossier `models/`)
- `ml_model.joblib` : Pipeline ML complet (TF-IDF + Naive Bayes)
- `vectorizer.joblib` : Vectorizer TF-IDF du modÃ¨le ML
- `dl_model.h5` : ModÃ¨le LSTM bidirectionnel
- `dl_label_encoder.pkl` : LabelEncoder du modÃ¨le DL
- `autoencoder_summarizer.h5` : Autoencodeur pour le rÃ©sumÃ©
- `shared_tokenizer.pkl` : Tokenizer partagÃ© pour les modÃ¨les DL

### MÃ©triques Ã‰valuÃ©es
- **Accuracy** : PrÃ©cision globale de classification
- **Precision** : PrÃ©cision par classe
- **Recall** : Rappel par classe
- **F1-Score** : Score F1 par classe
- **Matrice de confusion** : Visualisation des erreurs
- **Courbes d'apprentissage** : Ã‰volution de l'entraÃ®nement

### Visualisations Individuelles
- `ml_confusion_matrix.png` : Matrice de confusion du modÃ¨le ML
- `ml_learning_curve.png` : Courbe d'apprentissage du modÃ¨le ML
- `ml_metrics_by_class.png` : MÃ©triques par classe (ML)
- `dl_confusion_matrix.png` : Matrice de confusion du modÃ¨le DL
- `dl_learning_curves.png` : Courbes d'apprentissage du modÃ¨le DL
- `dl_metrics_by_class.png` : MÃ©triques par classe (DL)
- `autoencoder_learning_curves.png` : Courbes d'apprentissage de l'autoencodeur
- `autoencoder_architecture.png` : Architecture de l'autoencodeur

### Visualisations Comparatives
- `model_comparison_classification.png` : Comparaison des mÃ©triques de classification
- `learning_curves_comparison.png` : Comparaison des courbes d'apprentissage
- `performance_summary.png` : RÃ©sumÃ© des performances globales
- `evaluation_report.txt` : Rapport d'Ã©valuation complet

------------------------------------------------------------
Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre du cours de Natural Language Processing enseignÃ© par Nicolas Miotto, Ã  l'Ã©cole Ynov Toulouse
------------------------------------------------------------
